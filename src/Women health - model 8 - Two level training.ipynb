{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class encode_categorical_feature:\n",
    "    def __init__(self,feature):\n",
    "        self.f_set = []\n",
    "        self.feature = feature\n",
    "    def fit(self,data):\n",
    "        if self.feature in data.columns:\n",
    "            self.f_set = sorted(list(data[self.feature].unique()))\n",
    "            f_values   = data[self.feature].apply(lambda x: [self.f_set.index(x)])\n",
    "            self.encoder = OneHotEncoder().fit(list(f_values))\n",
    "    def transform(self,data):\n",
    "        if not self.f_set:\n",
    "            return data\n",
    "        f_values  = data[self.feature].apply(lambda x: [self.f_set.index(x)])\n",
    "        f_encoded = self.encoder.transform(list(f_values)).toarray()\n",
    "        f_df      = pd.DataFrame(f_encoded, columns=[self.feature+'_'+str(x) for x in self.f_set])\n",
    "        new_data  = pd.concat([data.reset_index(drop=True),f_df], axis=1)\n",
    "        new_data.drop(self.feature, axis=1, inplace=True)\n",
    "        return new_data\n",
    "\n",
    "def preprocess_data(train_data, test_data):\n",
    "    t = encode_categorical_feature('religion')\n",
    "    t.fit(train_data)\n",
    "    train_data = t.transform(train_data)\n",
    "    test_data  = t.transform(test_data)\n",
    "    \n",
    "    features = [x for x in train_data.columns if x not in ['patientID', 'geo','segment','subgroup','combined_label', 'INTNR' ]]\n",
    "    target = 'combined_label'\n",
    "    # train_data\n",
    "    train_data['combined_label'] = 100*train_data['geo'] + 10*train_data['segment'] + train_data['subgroup']\n",
    "    train_data = train_data.fillna(0)\n",
    "    X_train,y_train = train_data[features],train_data[target]\n",
    "    # test_data\n",
    "    test_data = test_data.fillna(0)\n",
    "    X_test = test_data[features]\n",
    "    # select features\n",
    "    selection1 = ['DISTRICT', u'tribe', u'REGION_PROVINCE', u'babydoc', u'foodinsecurity', u'religion_Buddhist', u'india', u'hindu', u'religion_Hindu', u'religion_Russian/Easter', u'educ', u'Debut', u'literacy', u'christian', u'hivknow', u'ModCon', u'age', u'thrasher', u'usecondom', u'religion_Other Christia', u'religion_Muslim', u'muslim', u'lowlit', u'multpart', u'motorcycle', u'CHILDREN', u'LaborDeliv']\n",
    "    selection2 = [u'christian', u'hindu', u'REGION_PROVINCE', u'DISTRICT', u'electricity', u'age', u'tribe', u'foodinsecurity', u'EVER_HAD_SEX', u'EVER_BEEN_PREGNANT', u'CHILDREN', u'india', u'married', u'multpart', u'educ', u'literacy', u'LaborDeliv', u'babydoc', u'Debut', u'ModCon', u'usecondom', u'hivknow', u'religion_Buddhist', u'religion_Hindu', u'religion_Russian/Easter']\n",
    "    selection3 = [u'DISTRICT', u'tribe', u'REGION_PROVINCE', u'babydoc', u'india', u'educ', u'Debut', u'literacy', u'hivknow', u'ModCon', u'age', u'usecondom', u'multpart', u'CHILDREN', u'LaborDeliv', u'married']\n",
    "    selected_features = selection1+selection2+selection3\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "#     return X_train,y_train,X_test\n",
    "    return X_train.values,y_train.values,X_test.values\n",
    "\n",
    "def gen_models():\n",
    "    def gen_models_rf(parameters):\n",
    "        models = []\n",
    "        for n in parameters['n_estimators']:\n",
    "            for m in parameters['max_depth']:\n",
    "                models.append(RandomForestClassifier(n_estimators=n, max_depth=m, random_state=0))\n",
    "        return models\n",
    "    def gen_models_gbm(parameters):\n",
    "        models = []\n",
    "        for n in parameters['n_estimators']:\n",
    "            for m in parameters['max_depth']:\n",
    "                for l in parameters['learning_rate']:\n",
    "                    models.append(GradientBoostingClassifier(n_estimators=n, max_depth=m, random_state=0))\n",
    "        return models\n",
    "    def gen_models_log(parameters):\n",
    "        models = []\n",
    "        for p in parameters['penalty']:\n",
    "            for c in parameters['C']:\n",
    "                models.append(linear_model.LogisticRegression(penalty=p, C=c))\n",
    "        return models\n",
    "\n",
    "    def gen_models_svm(parameters):\n",
    "        models = []\n",
    "        for c in parameters['C']:\n",
    "            for k in parameters['kernel']:\n",
    "                if 'gamma' in parameters:\n",
    "                    for g in parameters['gamma']:\n",
    "                        models.append(svm.SVC(C=c, kernel=k, gamma=g, probability=True))\n",
    "                else:\n",
    "                    models.append(svm.SVC(C=c, kernel=k, probability=True))\n",
    "\n",
    "        return models\n",
    "\n",
    "    param_gbm = { 'n_estimators':[50, 100,200],\n",
    "                  'learning_rate':[0.1,1.0],\n",
    "                  'max_depth':[1,2,3]}\n",
    "    param_rf  = {'n_estimators':[100,200,500,800,1000,],\n",
    "                  'max_depth':[1,2,4,6,8,10,13]}\n",
    "    param_svc = [\n",
    "                  {'C':[0.1, 1, 10, 100], 'kernel': ['linear']},\n",
    "                  {'C':[0.1, 1, 10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "                ]\n",
    "    param_log = {'penalty':('l1','l2'), \n",
    "                  'C':[0.1, 1, 10, 100]}\n",
    "    models  = gen_models_gbm(param_gbm)\n",
    "    models += gen_models_rf(param_rf)\n",
    "    models += gen_models_svm(param_svc[0])\n",
    "    models += gen_models_svm(param_svc[1])\n",
    "    models += gen_models_log(param_log)\n",
    "    selection_ind = [45, 38, 52, 31, 24, 16, 17, 30, 14, 15, 37]\n",
    "    models = [models[i] for i in selection_ind]\n",
    "    return models\n",
    "\n",
    "\n",
    "class model_collection:\n",
    "    def __init__(self, models):\n",
    "        self.models = models[:]\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes = np.unique(y_train)\n",
    "        for i in range(len(self.models)):\n",
    "            self.models[i].fit(X_train,y_train)\n",
    "    def predict_proba(self, X_test):\n",
    "        self.y_proba = []\n",
    "        for m in self.models:\n",
    "            self.y_proba.append(m.predict_proba(X_test))\n",
    "        return self.y_proba\n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = []\n",
    "        for m in self.models:\n",
    "            self.y_pred.append(m.predict(X_test))\n",
    "        return self.y_pred\n",
    "    \n",
    "\n",
    "class combined_model:\n",
    "    def __init__(self):\n",
    "        models = gen_models()\n",
    "        self.model_col = model_collection(models)\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model_col.fit(X_train, y_train)\n",
    "    def predict(self, X_test):\n",
    "        y_pred  = self.model_col.predict(X_test)\n",
    "        y_pred  = np.array(y_pred).T\n",
    "        y_proba = self.model_col.predict_proba(X_test)\n",
    "        y_proba_max = np.array([[row.max() for row in yy] for yy in y_proba]).T\n",
    "        \n",
    "        \n",
    "        # The sum of probabilities\n",
    "        y_proba_sum = np.zeros_like(y_proba[0])\n",
    "        for yy in y_proba:\n",
    "            y_proba_sum += yy\n",
    "        y_pred_sum = [self.model_col.classes[row.argmax()] for row in y_proba_sum]\n",
    "        \n",
    "        self.prediction = y_pred_sum\n",
    "#         print self.model_col.models[2]\n",
    "        return self.prediction\n",
    "        \n",
    "        \n",
    "def azureml_main(train_data = None, test_data = None):\n",
    "    features = [x for x in train_data.columns if x not in ['geo','segment','subgroup' ]]\n",
    "    test_data = test_data[features]\n",
    "    \n",
    "    X_train,y_train,X_test = preprocess_data(train_data, test_data)\n",
    "    \n",
    "    m = combined_model()\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    \n",
    "#     test_data['Geo_Pred']      = y_pred/100\n",
    "#     test_data['Segment_Pred']  = y_pred/10%10\n",
    "#     test_data['Subgroup_Pred'] = y_pred%10\n",
    "    \n",
    "#     return test_data[['patientID','Geo_Pred','Segment_Pred','Subgroup_Pred']]\n",
    "\n",
    "#     output = pd.DataFrame()\n",
    "#     output['patientID']=test_data['patientID']\n",
    "#     output['Geo_Pred']      = y_pred/100\n",
    "#     output['Segment_Pred']  = y_pred/10%10\n",
    "#     output['Subgroup_Pred'] = y_pred%10\n",
    "#     return output\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# data = pd.read_csv('../datasets/WomenHealth_Training.csv')\n",
    "# from sklearn.cross_validation import KFold\n",
    "# scores = []\n",
    "# for train_ind, valid_ind in KFold(data.shape[0], n_folds=4): \n",
    "#     train_data = data.loc[train_ind,:]\n",
    "#     test_data  = data.loc[valid_ind,:]\n",
    "#     y_test = 100*test_data['geo'] + 10*test_data['segment'] + test_data['subgroup']\n",
    "#     y_pred = azureml_main(train_data, test_data)\n",
    "#     scores.append(sklearn.metrics.accuracy_score(y_pred, y_test))\n",
    "#     print scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "data = pd.read_csv('../datasets/WomenHealth_Training.csv')\n",
    "nrows = data.shape[0]\n",
    "train_valid_ind = random.sample(range(nrows),int(nrows*0.9))\n",
    "train_ind = random.sample(train_valid_ind,int(len(train_valid_ind)*0.5))\n",
    "valid_ind = [i for i in train_valid_ind if i not in train_ind]\n",
    "test_ind  = [i for i in range(nrows) if i not in train_valid_ind]\n",
    "\n",
    "train_data = data.ix[train_ind,:]\n",
    "valid_data  = data.ix[valid_ind,:]\n",
    "test_data  = data.ix[test_ind,:]\n",
    "\n",
    "X_train, y_train, X_test = preprocess_data(train_data, test_data)\n",
    "X_valid, y_valid, X_test = preprocess_data(valid_data, test_data)\n",
    "\n",
    "models_all = gen_models()\n",
    "model_level_1 = sklearn.base.clone(models_all[2])\n",
    "model_level_1.fit(X_train,y_train)\n",
    "y_valid_pred  = model_level_1.predict(X_valid)\n",
    "y_valid_pred = np.array(y_valid_pred).T\n",
    "y_valid_proba = model_level_1.predict_proba(X_valid)\n",
    "y_valid_proba_max = np.array([row.max() for row in y_valid_proba]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = 100*test_data['geo'] + 10*test_data['segment'] + test_data['subgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred  = model_level_1.predict(X_test)\n",
    "y_test_pred  = np.array(y_test_pred).T\n",
    "y_test_proba = model_level_1.predict_proba(X_test)\n",
    "y_test_proba_max = np.array([row.max() for row in y_test_proba]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858645351283\n",
      "0.82797731569\n"
     ]
    }
   ],
   "source": [
    "print sklearn.metrics.accuracy_score(y_valid,y_valid_pred)\n",
    "print sklearn.metrics.accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00   0.8586   2377 \n",
      "0.05   0.8586   2377 \n",
      "0.10   0.8586   2377 \n",
      "0.15   0.8586   2377 \n",
      "0.20   0.8590   2376 \n",
      "0.25   0.8596   2371 \n",
      "0.30   0.8625   2357 \n",
      "0.35   0.8711   2319 \n",
      "0.40   0.8825   2246 \n",
      "0.45   0.8957   2158 \n",
      "0.50   0.9170   2036 \n",
      "0.55   0.9362   1913 \n",
      "0.60   0.9540   1804 \n",
      "0.65   0.9641   1700 \n",
      "0.70   0.9725   1564 \n",
      "0.75   0.9805   1435 \n",
      "0.80   0.9839   1304 \n",
      "0.85   0.9842   1137 \n",
      "0.90   0.9859    925 \n",
      "0.95   0.9950    597 \n"
     ]
    }
   ],
   "source": [
    "for p in np.linspace(0,0.95,20):\n",
    "    ind = y_valid_proba_max>p\n",
    "    print \"%.2f   %.4f   %4d \"%(p, sklearn.metrics.accuracy_score(y_valid_pred[ind],y_valid[ind]), sum(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824197    0.621212    0.831758\n",
      "0.824197    0.621212    0.831758\n",
      "0.824197    0.606061    0.826087\n",
      "0.824197    0.636364    0.837429\n",
      "0.824197    0.616162    0.829868\n",
      "0.824197    0.565657    0.810964\n",
      "0.824197    0.565657    0.810964\n",
      "0.824197    0.611111    0.827977\n",
      "0.824197    0.535354    0.799622\n",
      "0.824197    0.535354    0.799622\n",
      "0.824197    0.606061    0.826087\n"
     ]
    }
   ],
   "source": [
    "p_cut = 0.7\n",
    "l2_valid_ind = y_valid_proba_max<p_cut\n",
    "X_train_2 = X_valid[l2_valid_ind,:]\n",
    "y_train_2 = y_valid[l2_valid_ind]\n",
    "\n",
    "l2_test_ind = y_test_proba_max<p_cut\n",
    "X_test_2 = X_test[l2_test_ind,:]\n",
    "\n",
    "for model2 in models_all:\n",
    "    model2.fit(X_train_2,y_train_2)\n",
    "    y_test_pred_tmp = y_test_pred.copy()\n",
    "#     print sklearn.metrics.accuracy_score(y_test,y_test_pred)\n",
    "    y_test_pred_tmp[l2_test_ind]=model2.predict(X_test_2)\n",
    "    print '%.6f    %.6f    %.6f'%(sklearn.metrics.accuracy_score(y_test,y_test_pred),\n",
    "                                  sklearn.metrics.accuracy_score(y_test[l2_test_ind],y_test_pred_tmp[l2_test_ind]),\n",
    "                                  sklearn.metrics.accuracy_score(y_test,y_test_pred_tmp))\n",
    "\n",
    "# for m in models_all:\n",
    "#     m.fit(X_train_2,y_train_2)\n",
    "#     y_test_pred_tmp = y_test_pred[:]\n",
    "#     y_test_pred_tmp[l2_test_ind]=m.predict(X_test_2)\n",
    "#     print '%.4f    %.4f'%(sklearn.metrics.accuracy_score(y_test,y_test_pred),\n",
    "#                           sklearn.metrics.accuracy_score(y_test,y_test_pred_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/WomenHealth_Training.csv')\n",
    "train_ind, valid_ind, y_train_ind, y_valid_ind = sklearn.cross_validation.train_test_split(range(data.shape[0]),range(data.shape[0]),test_size=0.25, random_state=42)\n",
    "train_valid_data = data.loc[train_ind,:]\n",
    "test_data  = data.loc[valid_ind,:]\n",
    "X_train_valid,y_train_valid,X_test = preprocess_data(train_valid_data, test_data)\n",
    "y_test = 100*test_data['geo'] + 10*test_data['segment'] + test_data['subgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 accuracy 0.6 0.859954579864\n",
      "0.856169568509\n",
      "0.853898561696\n",
      "0.85692657078\n",
      "0.856169568509\n",
      "0.860711582135\n",
      "0.850870552612\n",
      "0.850870552612\n",
      "0.862225586677\n",
      "0.851627554883\n",
      "0.851627554883\n",
      "0.859954579864\n",
      "model 1 accuracy 0.7 0.859954579864\n",
      "0.853141559425\n",
      "0.854655563967\n",
      "0.850113550341\n",
      "0.85692657078\n",
      "0.860711582135\n",
      "0.84935654807\n",
      "0.84935654807\n",
      "0.850113550341\n",
      "0.850113550341\n",
      "0.850113550341\n",
      "0.855412566238\n",
      "model 1 accuracy 0.8 0.859954579864\n",
      "0.856169568509\n",
      "0.859954579864\n",
      "0.855412566238\n",
      "0.859197577593\n",
      "0.859954579864\n",
      "0.846328538986\n",
      "0.846328538986\n",
      "0.857683573051\n",
      "0.853141559425\n",
      "0.853141559425\n",
      "0.853898561696\n",
      "model 1 accuracy 0.9 0.859954579864\n",
      "0.858440575322\n",
      "0.859197577593\n",
      "0.854655563967\n",
      "0.856169568509\n",
      "0.862225586677\n",
      "0.855412566238\n",
      "0.855412566238\n",
      "0.857683573051\n",
      "0.85692657078\n",
      "0.85692657078\n",
      "0.855412566238\n",
      "model 1 accuracy 0.95 0.859954579864\n",
      "0.854655563967\n",
      "0.854655563967\n",
      "0.856169568509\n",
      "0.859197577593\n",
      "0.854655563967\n",
      "0.855412566238\n",
      "0.855412566238\n",
      "0.852384557154\n",
      "0.858440575322\n",
      "0.858440575322\n",
      "0.852384557154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "for p_cut in [0.6,0.7,0.8, 0.9,0.95]:\n",
    "    model_1 = sklearn.base.clone(models_all[2])\n",
    "    model_2 = sklearn.base.clone(models_all[2])\n",
    "    level_2_X = []\n",
    "    level_2_y = []\n",
    "    for train_ind, valid_ind in KFold(X_train_valid.shape[0], n_folds=4): \n",
    "        X_train  = X_train_valid[train_ind,:]\n",
    "        X_valid  = X_train_valid[valid_ind,:]\n",
    "        y_train  = y_train_valid[train_ind]\n",
    "        y_valid  = y_train_valid[valid_ind]\n",
    "        model_1.fit(X_train, y_train)\n",
    "        y_valid_proba = model_1.predict_proba(X_valid)\n",
    "        y_valid_proba_max = np.array([row.max() for row in y_valid_proba]).T\n",
    "        level_2_ind = y_valid_proba_max<p_cut\n",
    "        level_2_X.append(X_valid[level_2_ind,:])\n",
    "        level_2_y.append(y_valid[level_2_ind])\n",
    "    level_2_X = np.concatenate(level_2_X, axis=0)\n",
    "    level_2_y = np.concatenate(level_2_y, axis=0)\n",
    "\n",
    "    model_1.fit(X_train_valid, y_train_valid)\n",
    "    model_2.fit(level_2_X,level_2_y)\n",
    "    y_test_pred = model_1.predict(X_test)\n",
    "    print 'model 1 accuracy', p_cut, sklearn.metrics.accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    y_test_proba = model_1.predict_proba(X_test)\n",
    "    y_test_proba_max = np.array([row.max() for row in y_test_proba]).T\n",
    "    level_2_ind = y_test_proba_max<p_cut\n",
    "    for m in models_all:\n",
    "        m.fit(level_2_X,level_2_y)\n",
    "        y_test_pred[level_2_ind]=m.predict(X_test[level_2_ind,:])\n",
    "        print sklearn.metrics.accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
